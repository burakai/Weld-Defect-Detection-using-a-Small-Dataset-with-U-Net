{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmhrKkkE4l4A407eMChh4A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# Mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Adjusting working directory\n","import os\n","root_dir = \"/content/drive/My Drive/\"\n","target_dir = \"/colab notebooks\"\n","cwd = os.chdir(root_dir + target_dir)\n","!pwd\n","\n","# Check type of GPU and VRAM available\n","!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J3qzVOHrJ8jj","executionInfo":{"status":"ok","timestamp":1672585705334,"user_tz":-180,"elapsed":28385,"user":{"displayName":"Burak Kılıç","userId":"08570120524117355643"}},"outputId":"0fc63fdc-69b9-4ac0-bea7-90f3fc1a8206"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/colab notebooks\n","Tesla T4, 15109 MiB, 15109 MiB\n"]}]},{"cell_type":"code","source":["import time\n","from PIL import Image\n","import numpy as np\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms.functional as TF\n","from torchvision import datasets, transforms\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm import tqdm"],"metadata":{"id":"scaRdYHfJ1aZ","executionInfo":{"status":"ok","timestamp":1672585712049,"user_tz":-180,"elapsed":6717,"user":{"displayName":"Burak Kılıç","userId":"08570120524117355643"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Hyperparameters, etc.\n","LEARNING_RATE = 1e-4\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","BATCH_SIZE = 16\n","NUM_EPOCHS = 10\n","NUM_WORKERS = 2\n","IMAGE_HEIGHT = 160\n","IMAGE_WIDTH = 240\n","PIN_MEMORY = True\n","LOAD_MODEL = False\n","TRAIN_IMG_DIR = \"data/train_images/\"\n","TRAIN_MASK_DIR = \"data/train_masks/\"\n","VAL_IMG_DIR = \"data/val_images/\"\n","VAL_MASK_DIR = \"data/val_masks/\""],"metadata":{"id":"ZV15SEmDJ68w","executionInfo":{"status":"ok","timestamp":1672592746697,"user_tz":-180,"elapsed":421,"user":{"displayName":"Burak Kılıç","userId":"08570120524117355643"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class MyDataset(Dataset):\n","    def __init__(self, image_dir, mask_dir, transform=None):\n","        self.image_dir = image_dir\n","        self.mask_dir = mask_dir\n","        self.transform = transform\n","        self.images = os.listdir(image_dir)\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, index):\n","        img_path = os.path.join(self.image_dir, self.images[index])\n","        mask_path = os.path.join(self.mask_dir, self.images[index].replace(\".png\", \"_mask.png\"))\n","        image = np.array(Image.open(img_path).convert(\"RGB\"))\n","        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n","        mask[mask == 255.0] = 1.0\n","\n","        if self.transform is not None:\n","            augmentations = self.transform(image=image, mask=mask)\n","            image = augmentations[\"image\"]\n","            mask = augmentations[\"mask\"]\n","\n","        return image, mask"],"metadata":{"id":"8Kwnux64KRk1","executionInfo":{"status":"ok","timestamp":1672586156254,"user_tz":-180,"elapsed":439,"user":{"displayName":"Burak Kılıç","userId":"08570120524117355643"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Define a class for \"Double Convolution\" operation\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DoubleConv, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","# Define a class for UNET architecture\n","class UNET(nn.Module):\n","    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n","        super(UNET, self).__init__()\n","        self.ups = nn.ModuleList()\n","        self.downs = nn.ModuleList()\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Down\n","        for feature in features:\n","            self.downs.append(DoubleConv(in_channels, feature))\n","            in_channels = feature\n","\n","        # Up\n","        for feature in reversed(features):\n","            self.ups.append(\n","                nn.ConvTranspose2d(\n","                    feature*2, feature, kernel_size=2, stride=2\n","                )\n","            )\n","            self.ups.append(DoubleConv(feature*2, feature))\n","\n","        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n","        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        skip_connections = []\n","\n","        for down in self.downs:\n","            x = down(x)\n","            skip_connections.append(x)\n","            x = self.pool(x)\n","\n","        x = self.bottleneck(x)\n","        skip_connections = skip_connections[::-1]\n","\n","        for idx in range(0, len(self.ups), 2):\n","            x = self.ups[idx](x)\n","            skip_connection = skip_connections[idx//2]\n","\n","            if x.shape != skip_connection.shape:\n","                x = TF.resize(x, size=skip_connection.shape[2:])\n","\n","            concat_skip = torch.cat((skip_connection, x), dim=1)\n","            x = self.ups[idx+1](concat_skip)\n","\n","        return self.final_conv(x)\n","\n","# Define (function) test() for checking if the dimensions match\n","def test():\n","    x = torch.randn((3, 1, 366, 366))\n","    model = UNET(in_channels=1, out_channels=1)\n","    preds = model(x)\n","    print(preds.shape)\n","    print(x.shape)\n","    assert preds.shape == x.shape"],"metadata":{"id":"Plo3iD98KX5X","executionInfo":{"status":"ok","timestamp":1672585712806,"user_tz":-180,"elapsed":2,"user":{"displayName":"Burak Kılıç","userId":"08570120524117355643"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4dZTv0EoOutV","executionInfo":{"status":"ok","timestamp":1672585722191,"user_tz":-180,"elapsed":9387,"user":{"displayName":"Burak Kılıç","userId":"08570120524117355643"}},"outputId":"955aae67-4669-4161-cfbd-dca763ca6acd"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 1, 366, 366])\n","torch.Size([3, 1, 366, 366])\n"]}]},{"cell_type":"code","source":["def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    torch.save(state, filename)\n","\n","def load_checkpoint(checkpoint, model):\n","    print(\"=> Loading checkpoint\")\n","    model.load_state_dict(checkpoint[\"state_dict\"])"],"metadata":{"id":"dHz9twQMKtsG","executionInfo":{"status":"ok","timestamp":1672585722192,"user_tz":-180,"elapsed":6,"user":{"displayName":"Burak Kılıç","userId":"08570120524117355643"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def get_loaders(\n","    train_dir,\n","    train_maskdir,\n","    val_dir,\n","    val_maskdir,\n","    batch_size,\n","    train_transform,\n","    val_transform,\n","    num_workers=4,\n","    pin_memory=True,\n","):\n","    train_ds = MyDataset(\n","        image_dir=train_dir,\n","        mask_dir=train_maskdir,\n","        transform=train_transform,\n","    )\n","\n","    train_loader = DataLoader(\n","        train_ds,\n","        batch_size=batch_size,\n","        num_workers=num_workers,\n","        pin_memory=pin_memory,\n","        shuffle=True,\n","    )\n","\n","    val_ds = MyDataset(\n","        image_dir=val_dir,\n","        mask_dir=val_maskdir,\n","        transform=val_transform,\n","    )\n","\n","    val_loader = DataLoader(\n","        val_ds,\n","        batch_size=batch_size,\n","        num_workers=num_workers,\n","        pin_memory=pin_memory,\n","        shuffle=False,\n","    )\n","\n","    return train_loader, val_loader"],"metadata":{"id":"eSaDDGkUKxF8","executionInfo":{"status":"ok","timestamp":1672585722192,"user_tz":-180,"elapsed":6,"user":{"displayName":"Burak Kılıç","userId":"08570120524117355643"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def check_accuracy(loader, model, device=DEVICE):\n","    num_correct = 0\n","    num_pixels = 0\n","    dice_score = 0\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device)\n","            y = y.to(device).unsqueeze(1)\n","            preds = torch.sigmoid(model(x))\n","            preds = (preds > 0.5).float()\n","            num_correct += (preds == y).sum()\n","            num_pixels += torch.numel(preds)\n","            dice_score += (2 * (preds * y).sum()) / (\n","                (preds + y).sum() + 1e-8\n","            )\n","\n","    print(\n","        f\"Got {num_correct}/{num_pixels} with accuracy {num_correct/num_pixels*100:.2f}\"\n","    )\n","    print(f\"Dice score: {dice_score/len(loader)}\")\n","    writer = SummaryWriter()\n","\n","    for n_iter in range(100):\n","        # writer.add_scalar('Loss/train', loss, n_iter)\n","        # writer.add_scalar('Loss/test', loss, n_iter)\n","        writer.add_scalar('Dice_score/train', dice_score/len(loader), n_iter)\n","\n","    model.train()"],"metadata":{"id":"ke86kTfjK3QC","executionInfo":{"status":"ok","timestamp":1672593830189,"user_tz":-180,"elapsed":572,"user":{"displayName":"Burak Kılıç","userId":"08570120524117355643"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"id":"aYPpprWwJyei","executionInfo":{"status":"ok","timestamp":1672585722192,"user_tz":-180,"elapsed":5,"user":{"displayName":"Burak Kılıç","userId":"08570120524117355643"}}},"outputs":[],"source":["def save_predictions_as_imgs(\n","    loader, model, folder=\"saved_images/\", device=DEVICE\n","):\n","    model.eval()\n","    for idx, (x, y) in enumerate(loader):\n","        x = x.to(device=device)\n","        with torch.no_grad():\n","            preds = torch.sigmoid(model(x))\n","            preds = (preds > 0.5).float()\n","        torchvision.utils.save_image(\n","            preds, f\"{folder}/pred_{idx}.png\"\n","        )\n","        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}{idx}.png\")\n","        \n","    model.train()"]},{"cell_type":"code","source":["def train_fn(loader, model, optimizer, loss_fn, scaler):\n","    \n","    loop = tqdm(loader)\n","\n","    for batch_idx, (data, targets) in enumerate(loop):\n","        data = data.to(device=DEVICE)\n","        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n","\n","        # forward\n","        with torch.cuda.amp.autocast():\n","            predictions = model(data)\n","            loss = loss_fn(predictions, targets)\n","\n","        # backward\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        # update tqdm loop\n","        loop.set_postfix(loss=loss.item())\n","\n","        for n_iter in range(100):\n","            # writer.add_scalar('Loss/train', loss, n_iter)\n","            writer.add_scalar('Loss/test', loss, n_iter)"],"metadata":{"id":"ynxcYndbK92Y","executionInfo":{"status":"ok","timestamp":1672593840413,"user_tz":-180,"elapsed":1,"user":{"displayName":"Burak Kılıç","userId":"08570120524117355643"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def main():\n","    train_transform = A.Compose(\n","        [\n","            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n","            A.Rotate(limit=35, p=1.0),\n","            A.HorizontalFlip(p=0.5),\n","            A.VerticalFlip(p=0.1),\n","            A.Normalize(\n","                mean=[0.0, 0.0, 0.0],\n","                std=[1.0, 1.0, 1.0],\n","                max_pixel_value=255.0,\n","            ),\n","            ToTensorV2(),\n","        ],\n","    )\n","\n","    val_transforms = A.Compose(\n","        [\n","            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n","            A.Normalize(\n","                mean=[0.0, 0.0, 0.0],\n","                std=[1.0, 1.0, 1.0],\n","                max_pixel_value=255.0,\n","            ),\n","            ToTensorV2(),\n","        ],\n","    )\n","\n","    model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n","\n","    loss_fn = nn.BCEWithLogitsLoss()\n","    # loss_fn = nn.CrossEntropyLoss()\n","    # optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n","    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","    train_loader, val_loader = get_loaders(\n","        TRAIN_IMG_DIR,\n","        TRAIN_MASK_DIR,\n","        VAL_IMG_DIR,\n","        VAL_MASK_DIR,\n","        BATCH_SIZE,\n","        train_transform,\n","        val_transforms,\n","        NUM_WORKERS,\n","        PIN_MEMORY,\n","    )\n","\n","    if LOAD_MODEL:\n","        load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\n","\n","    check_accuracy(val_loader, model, device=DEVICE)\n","    scaler = torch.cuda.amp.GradScaler()\n","\n","    for epoch in range(NUM_EPOCHS):\n","        train_fn(train_loader, model, optimizer, loss_fn, scaler)\n","\n","        # Save model\n","        checkpoint = {\n","            \"state_dict\": model.state_dict(),\n","            \"optimizer\": optimizer.state_dict(),\n","        }\n","        save_checkpoint(checkpoint)\n","\n","        # Check accuracy\n","        check_accuracy(val_loader, model, device=DEVICE)\n","\n","        # Print some examples\n","        save_predictions_as_imgs(\n","            val_loader, model, folder=\"saved_images/\", device=DEVICE\n","\n","        )"],"metadata":{"id":"J1BpwwHDKimE","executionInfo":{"status":"ok","timestamp":1672585722193,"user_tz":-180,"elapsed":5,"user":{"displayName":"Burak Kılıç","userId":"08570120524117355643"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["tic = time.time()\n","\n","main()\n","\n","toc = time.time()\n","total_time = toc - tic\n","print(f\"Executed in {total_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Th64LRJ3LD0w","outputId":"87c34117-0abc-4a89-9b44-146009eac5e5","executionInfo":{"status":"ok","timestamp":1672594150752,"user_tz":-180,"elapsed":303866,"user":{"displayName":"Burak Kılıç","userId":"08570120524117355643"}}},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Got 280500/1267200 with accuracy 22.14\n","Dice score: 0.3600223958492279\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:20<00:00,  2.29s/it, loss=0.528]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","Got 280500/1267200 with accuracy 22.14\n","Dice score: 0.3600223958492279\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:18<00:00,  2.07s/it, loss=0.374]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","Got 570524/1267200 with accuracy 45.02\n","Dice score: 0.41632699966430664\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:18<00:00,  2.06s/it, loss=0.344]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","Got 884685/1267200 with accuracy 69.81\n","Dice score: 0.06821933388710022\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:18<00:00,  2.06s/it, loss=0.323]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","Got 946750/1267200 with accuracy 74.71\n","Dice score: 0.06546026468276978\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:20<00:00,  2.29s/it, loss=0.299]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","Got 1205642/1267200 with accuracy 95.14\n","Dice score: 0.6795578002929688\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:19<00:00,  2.13s/it, loss=0.283]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","Got 1221892/1267200 with accuracy 96.42\n","Dice score: 0.8660486936569214\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:18<00:00,  2.10s/it, loss=0.273]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","Got 1226611/1267200 with accuracy 96.80\n","Dice score: 0.9057869911193848\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:18<00:00,  2.09s/it, loss=0.28]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","Got 1217402/1267200 with accuracy 96.07\n","Dice score: 0.8875343203544617\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:18<00:00,  2.07s/it, loss=0.271]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","Got 1220099/1267200 with accuracy 96.28\n","Dice score: 0.8895386457443237\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9/9 [00:19<00:00,  2.21s/it, loss=0.263]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","Got 1231760/1267200 with accuracy 97.20\n","Dice score: 0.9043822288513184\n","Executed in 303.25 seconds\n"]}]},{"cell_type":"code","source":["writer = SummaryWriter()\n","\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","# trainset = datasets.MNIST('mnist_train', train=True, download=True, transform=transform)\n","# trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","# model = torchvision.models.resnet50(False)\n","# Have ResNet model take in grayscale rather than RGB\n","model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","images, labels = next(iter(trainloader))\n","\n","grid = torchvision.utils.make_grid(images)\n","writer.add_image('images', grid, 0)\n","writer.add_graph(model, images)\n","writer.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2t4Wojz9Jzh8","executionInfo":{"status":"ok","timestamp":1672592720145,"user_tz":-180,"elapsed":13723,"user":{"displayName":"Burak Kılıç","userId":"08570120524117355643"}},"outputId":"a8e53d8e-d486-48d8-e805-ead349441b5f"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"code","source":["from torch.utils.tensorboard import SummaryWriter\n","import numpy as np\n","\n","writer = SummaryWriter()\n","\n","for n_iter in range(100):\n","    # writer.add_scalar('Loss/train', loss, n_iter)\n","    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n","    writer.add_scalar('Dice_score/train', dice_score/len(loader), n_iter)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"8GDX8snyTY4e","executionInfo":{"status":"error","timestamp":1672593647085,"user_tz":-180,"elapsed":1081,"user":{"displayName":"Burak Kılıç","userId":"08570120524117355643"}},"outputId":"70818f59-e5a1-40ca-b3f8-b7052ad00442"},"execution_count":26,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-c110fcdc7ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# writer.add_scalar('Loss/train', loss, n_iter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss/test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dice_score/train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_score\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'dice_score' is not defined"]}]}]}